{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "# -*- coding:utf-8 -*-"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将标注的json文件合并为Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436, 11)\n",
      "(78, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_713518/560058268.py:143: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(\"output/文献标注/%s_%s.xls\" % (sped, col_ab))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 11)\n",
      "(690, 11)\n",
      "(289, 11)\n",
      "(153, 11)\n",
      "(153, 11)\n",
      "(221, 11)\n",
      "(221, 11)\n",
      "(78, 11)\n",
      "(436, 11)\n",
      "(289, 11)\n"
     ]
    }
   ],
   "source": [
    "# 主要功能：合并json文件中的标注为Excel\n",
    "# 次要功能：将标注选取文本过多的标注裁剪，尤其是Evidence\n",
    "# 次要功能：当有多个Evidence时，选取证据等级最高的一个\n",
    "input_path = \"input\"\n",
    "col_dic =  {\"证据等级\":\"evi\", \"样本量\":\"num\",\"患者性别\":\"gender\",\"年龄\":\"age\",\"免疫状态\":\"immu\"}\n",
    "col_dic = {\"是否致病\":\"pat\"}\n",
    "sped_l = [ele for ele in os.listdir(input_path) if \".\" not in ele]\n",
    "\n",
    "\n",
    "for col_name, col_ab in col_dic.items():\n",
    "    \n",
    "    for sped in sped_l:\n",
    "        \n",
    "        collection = {}\n",
    "        paper_l = [ i for i in os.listdir(\"%s/%s/outputs\" % (input_path, sped)) if \"json\" in i ]\n",
    "        \n",
    "        for paper in paper_l:\n",
    "            \n",
    "            # pattern 用于储存信息\n",
    "            pattern = {\n",
    "                \"物种名称\": \"\",\n",
    "                \"是否是致病菌\": \"\",\n",
    "                \"样本量\": \"\",\n",
    "                \"患者性别\": \"\",\n",
    "                \"年龄\": \"\",\n",
    "                \"免疫状态\": \"\",\n",
    "                \"预后\": \"\",\n",
    "                \"肺部基础疾病\": \"\",\n",
    "                \"证据等级\": \"\",\n",
    "            }\n",
    "            \n",
    "            # 读取json文件\n",
    "            with open(\"%s/%s/outputs/%s\" % (input_path, sped, paper),\n",
    "                    \"r\",encoding='UTF-8') as f:\n",
    "                ano = json.load(f)\n",
    "                \n",
    "            evi_list = []\n",
    "            evis_list = []\n",
    "            \n",
    "            pattern[\"物种名称\"] = ano[\"content\"].split(\"\\r\\n\")[0][8:]\n",
    "            if ano[\"outputs\"] != {}:\n",
    "                \n",
    "                # [\"A\"]为标注的类别\n",
    "                for i in ano[\"outputs\"][\"annotation\"][\"A\"]:\n",
    "                    \n",
    "                    if len(i) > 1:\n",
    "                        \n",
    "                        # 保存所有信息到pattern\n",
    "                        if i[\"name\"] in pattern.keys():\n",
    "                            pattern[i[\"name\"]] = i[\"value\"]\n",
    "                            \n",
    "                        # 获取用于判断证据等级大小的信息\n",
    "                        if i[\"name\"]  in col_name:\n",
    "                            evi_list.append(i[\"value\"])\n",
    "                            \n",
    "                # [\"T\"]为标注对应的类别的文本\n",
    "                for j in ano[\"outputs\"][\"annotation\"][\"T\"]:\n",
    "                    \n",
    "                    if (j is not None) and (len(j) > 1):\n",
    "                            \n",
    "                        # 获取标注的判断证据等级的文本\n",
    "                        if j[\"name\"] in col_name:\n",
    "                            evis_list.append(j[\"value\"])\n",
    "                            \n",
    "                            # 比较等级\n",
    "                            if len(evis_list) > 1:\n",
    "                                \n",
    "                                evi_new = evi_list[len(evis_list) - 1]\n",
    "                                evi_old = evi_list[len(evis_list) - 2]\n",
    "                                \n",
    "                                if evi_new < evi_old:\n",
    "                                    \n",
    "                                    pattern[col_name] == j[\"value\"]\n",
    "                                    pattern[\"answer\"] = j[\"value\"]\n",
    "                                    pattern[\"old_start\"] = j[\"start\"]\n",
    "                                    pattern[\"old_end\"] = j[\"end\"]\n",
    "                                    \n",
    "                                    # 获取证据等级所在的整个句子\n",
    "                                    anr = ano[\"content\"].replace(\"\\r\\n\", \"  \")\n",
    "                                    new_start = [\n",
    "                                        anr.rfind(\n",
    "                                            \"%s\" % k, 0, j[\"start\"])\n",
    "                                        for k in string.punctuation\n",
    "                                        if anr.rfind(\n",
    "                                            \"%s\" % k, 0, j[\"start\"]) > 0\n",
    "                                    ]\n",
    "                                    new_start.append(0)\n",
    "                                    new_start = np.max(new_start)\n",
    "                                    new_end = [\n",
    "                                        anr.find(\n",
    "                                            \"%s\" % k, j[\"end\"], -1)\n",
    "                                        for k in string.punctuation\n",
    "                                        if anr.find(\n",
    "                                            \"%s\" % k, j[\"end\"], -1) > 0\n",
    "                                    ]\n",
    "                                    new_end.append(len(anr) - 1)\n",
    "                                    new_end = np.min(new_end)\n",
    "                                    \n",
    "                                    evi_txt = anr[new_start +\n",
    "                                                            1:new_end + 1]\n",
    "                                    pattern[\"sup_evi\"] = evi_txt\n",
    "                                    pattern[\"new_start\"] = new_start + 1\n",
    "                                    pattern[\"new_end\"] = new_end + 1\n",
    "                                    \n",
    "                            else:\n",
    "                                pattern[\"answer\"] = j[\"value\"]\n",
    "                                pattern[\"old_start\"] = j[\"start\"]\n",
    "                                pattern[\"old_end\"] = j[\"end\"]\n",
    "                                \n",
    "                                anr = ano[\"content\"].replace(\"\\r\\n\", \"  \")\n",
    "                                new_start = [\n",
    "                                        anr.rfind(\n",
    "                                            \"%s\" % k, 0, j[\"start\"])\n",
    "                                        for k in string.punctuation\n",
    "                                        if anr.rfind(\n",
    "                                            \"%s\" % k, 0, j[\"start\"]) > 0\n",
    "                                    ]\n",
    "                                new_start.append(0)\n",
    "                                new_start = np.max(new_start)\n",
    "                                new_end = [\n",
    "                                    anr.find(\n",
    "                                        \"%s\" % k, j[\"end\"], -1)\n",
    "                                    for k in string.punctuation\n",
    "                                    if anr.find(\n",
    "                                        \"%s\" % k, j[\"end\"], -1) > 0\n",
    "                                ]\n",
    "                                new_end.append(len(anr) - 1)\n",
    "                                new_end = np.min(new_end)\n",
    "                                \n",
    "                                evi_txt = anr[new_start +\n",
    "                                                        1:new_end + 1]\n",
    "                                pattern[\"sup_evi\"] = evi_txt\n",
    "                                pattern[\"new_start\"] = new_start + 1\n",
    "                                pattern[\"new_end\"] = new_end + 1\n",
    "                                \n",
    "            pattern[\"full\"] = ano[\"content\"]\n",
    "            pattern[\"id\"] = 'https://pubmed.ncbi.nlm.nih.gov/%s/' % paper.replace(\".json\", \"\")\n",
    "            \n",
    "            collection[paper.replace(\".json\", \"\")] = pattern\n",
    "            \n",
    "        df = pd.DataFrame(collection).T\n",
    "        print(df.shape)\n",
    "        df.to_excel(\"output/文献标注/%s_%s.xls\" % (sped, col_ab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd5a5980a31967086eaababc5338e6a92d5792ba40cc4c910227acd610a4f48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
