{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdf90a5-fed9-400e-b068-df5f3e01777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from mkdir import mk_dir\n",
    "from bert_format import train_qa, test_qa, test_yn, bset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5c4ba",
   "metadata": {},
   "source": [
    "# 构建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92cd39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ll = [\n",
    "    [\"样本量\",\"num\",\"How many patients are ivolved in this study?\"],\n",
    "    [\"患者性别\",\"gender\",\"What's gender of the patient?\"],\n",
    "    [\"年龄\",\"age\",\"How old is patient?\"],\n",
    "    [\"免疫状态\",\"immu\",\"What's patients' immunity state?\"],\n",
    "    [\"证据等级\",\"evi\"],\n",
    "    [\"检测方式\",\"mes\"]]\n",
    "\n",
    "df = pd.read_excel(\"input/human_label.xlsx\",index_col=0)\n",
    "df = df.loc[df[\"是否是致病菌\"] == \"yes\",:]\n",
    "\n",
    "for col_l in col_ll:\n",
    "    \n",
    "    col_name = col_l[0]\n",
    "    col_ab = col_l[1]\n",
    "    \n",
    "    # 读取标注信息\n",
    "    qa = []\n",
    "    \n",
    "    for idx in df.index:\n",
    "\n",
    "        if (df.loc[idx, \"%s文本\" %col_name] != \"none\") & (df.loc[idx, \"%s\" %col_name] != \"none\"):\n",
    "            \n",
    "            if col_ab == \"evi\":\n",
    "                \"What kind of sample was used to isolated %s?\" %df.loc[idx, \"物种名称\"]\n",
    "            elif col_ab == \"mes\":\n",
    "                que = \"Which method was used to diagnose the infection of %s\" %df.loc[idx, \"物种名称\"]\n",
    "            else:\n",
    "                que = col_l[2]\n",
    "\n",
    "            res = re.search(r\"\\b%s\\b\"%str(df.loc[idx, \"%s文本\" % col_name]), df.loc[idx, \"Full\"].replace(\"\\n\",\"\"))\n",
    "            start = res.start()\n",
    "\n",
    "            # if col_ab == \"num\":\n",
    "\n",
    "                # if (abs(df.loc[idx, \"%s_start\" % col_ab] - start) > 10) & (len(df.loc[idx, \"Full\"])>df.loc[idx, \"%s_start\" % col_ab]):\n",
    "                #     print(start, df.loc[idx, \"%s_start\" % col_ab], df.loc[idx, \"%s文本\" % col_name],df.loc[idx, \"Full\"].replace(\"\\n\",\"\")[start-5:start+15] )\n",
    "                    \n",
    "            qa.append(\n",
    "                train_qa(\n",
    "                    str(idx), \n",
    "                    que,\n",
    "                    str(df.loc[idx, \"%s文本\" % col_name ]),\n",
    "                    start,\n",
    "                    df.loc[idx, \"Full\"].replace(\"\\n\",\"\"))\n",
    "            )\n",
    "    bset(qa, \"input/input_%s/\" % (col_ab) ,\"train_set.json\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d6dca",
   "metadata": {},
   "source": [
    "# 构建预测集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c6ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Pubmed_Search/search_results/search_results_pneumonia.txt\", \"r\") as f:\n",
    "    spec_papers_dic = json.loads(f.read())\n",
    "    \n",
    "# 加载判断了的病原菌信息\n",
    "prediction = json.load(open(\"output/output_pat/total_predictions.json\", 'r'))\n",
    "result = {}\n",
    "for i in prediction.keys():\n",
    "    paper_id = i.split(\":\")[0]\n",
    "    spec = i.split(\":\")[1]\n",
    "    ncbi = \"https://pubmed.ncbi.nlm.nih.gov/%s/\" % paper_id\n",
    "    result[i] = [paper_id, spec, prediction[i][1][0], ncbi]\n",
    "result = pd.DataFrame(result, index = [\"ID\", \"SPECIES\", \"rate\", \"link\"]).T\n",
    "prediction_extend = {'Bactology':{}, 'Mycology':{}, 'Virology':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "990d0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec_type in spec_papers_dic:\n",
    "    \n",
    "    for spec in spec_papers_dic[spec_type]:\n",
    "        \n",
    "        for k, v in prediction.items():\n",
    "            \n",
    "            spec = k.split(':')[1]\n",
    "            paper_id = k.split(':')[0]\n",
    "            \n",
    "            if spec in spec_papers_dic[spec_type]:\n",
    "                \n",
    "                if paper_id in spec_papers_dic[spec_type][spec]:\n",
    "                \n",
    "                    if v[1][0]>=0.5:\n",
    "                        \n",
    "                        if spec not in prediction_extend[spec_type]:\n",
    "                        \n",
    "                            prediction_extend[spec_type][spec] = {}\n",
    "                            prediction_extend[spec_type][spec][paper_id] = spec_papers_dic[spec_type][spec][paper_id]\n",
    "                            prediction_extend[spec_type][spec][paper_id][\"predition\"] = prediction[k][1][0]\n",
    "                        else:\n",
    "                            prediction_extend[spec_type][spec][paper_id] = spec_papers_dic[spec_type][spec][paper_id]\n",
    "                            prediction_extend[spec_type][spec][paper_id][\"predition\"] = prediction[k][1][0]\n",
    "\n",
    "with open(\"output/prediction_extend.json\", \"w\") as f:\n",
    "    json.dump(prediction_extend, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5875508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616 48731\n",
      "298 12222\n",
      "477 48360\n"
     ]
    }
   ],
   "source": [
    "for spec_type in prediction_extend:\n",
    "    spec_num = 0\n",
    "    paper_num = 0\n",
    "    for k,v in prediction_extend[spec_type].items():\n",
    "        if len(v) > 0:\n",
    "            spec_num = spec_num + 1\n",
    "            paper_num = paper_num + len(v)\n",
    "    print(spec_num, paper_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010c1a60-e4ee-4555-afcb-abf013736f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292821\n",
      "292821\n",
      "292821\n",
      "292821\n",
      "292821\n",
      "292821\n"
     ]
    }
   ],
   "source": [
    "with open(\"output/output_pat/prediction_extend.json\", \"r\") as f:\n",
    "    spec_papers_dic = json.load(f)\n",
    "\n",
    "# 根据上述筛选出的样本的数据集\n",
    "col_ll = [\n",
    "    [\"样本量\",\"num\",\"How many patients are ivolved in this study?\"],\n",
    "    [\"患者性别\",\"gender\",\"What's gender of the patient?\"],\n",
    "    [\"年龄\",\"age\",\"How old is patient?\"],\n",
    "    [\"免疫状态\",\"immu\",\"What's patients' immunity state?\"],\n",
    "    [\"证据等级\",\"evi\"],\n",
    "    [\"检测方式\",\"mes\"]]\n",
    "\n",
    "for col_l in col_ll:\n",
    "    \n",
    "    col_name = col_l[0]\n",
    "    col_ab = col_l[1]\n",
    "    \n",
    "    qa = []\n",
    "\n",
    "    for spec_type in spec_papers_dic:\n",
    "            \n",
    "        for spec in spec_papers_dic[spec_type]:\n",
    "            \n",
    "            for paper_id in spec_papers_dic[spec_type][spec]:\n",
    "                \n",
    "                if len(spec_papers_dic[spec_type][spec][paper_id][\"texts\"][\"Ab\"]) > 0:\n",
    "                    \n",
    "                    if col_ab == \"evi\":\n",
    "                        que = \"What kind of sample was used to isolated %s?\" % spec\n",
    "                    elif col_ab == \"mes\":\n",
    "                        que = \"Which method was used to diagnose the infection of %s\" % spec\n",
    "                    else:\n",
    "                        que = col_l[2]\n",
    "                    \n",
    "                    qa.append(test_qa(\n",
    "                        spec,\n",
    "                        que,\n",
    "                        spec_papers_dic[spec_type][spec][paper_id][\"texts\"][\"Ab\"]+\" \"+\n",
    "                        \" \".join(sum(spec_papers_dic[spec_type][spec][paper_id][\"Meshhead\"],[])) ))\n",
    "                \n",
    "    print(len(qa))\n",
    "    qasub = [qa[i:i + 50000] for i in range(0, len(qa), 50000)]\n",
    "    # for i in range(len(qasub)):\n",
    "        \n",
    "        # bset(qasub[i],\"input/input_%s/input_%s/\" % (col_ab,i),\"test_set.json\")\n",
    "        \n",
    "        # with open(\"input/input_%s/train_set.json\" % col_ab, \"r\") as f:\n",
    "        #     train = json.load(f)\n",
    "        # with open(\"input/input_%s/input_%s/train_set.json\" % (col_ab,i), \"w\") as f:\n",
    "        #     json.dump(train, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd5a5980a31967086eaababc5338e6a92d5792ba40cc4c910227acd610a4f48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
