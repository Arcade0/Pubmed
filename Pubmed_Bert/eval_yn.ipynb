{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import random\n",
    "from random import choice\n",
    "random.seed(10)\n",
    "# -*- coding:utf-8 -*\n",
    "import eval\n",
    "from mkdir import mk_dir\n",
    "from bert_format import bset,test_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10)\n",
    "# for col_ab in [\"age\", \"gender\",\"num\",\"evi\",\"immu\"]:\n",
    "for col_ab in ['pat']:\n",
    "\n",
    "    mk_dir(\"eval/evl_%s\" % (col_ab))\n",
    "\n",
    "    train_set = json.load(open(\"input/input_%s/train_set.json\" \\\n",
    "        %(col_ab), \"r\"))\n",
    "    train_qa = train_set['data'][0][\"paragraphs\"]\n",
    "\n",
    "    re = 0\n",
    "    for ttrain_qa,eval_qa in kf.split(train_qa):\n",
    "\n",
    "        re = re + 1\n",
    "        bset(\n",
    "            [train_qa[i] for i in ttrain_qa],\n",
    "            \"eval/evl_%s/input_%s/\" % (col_ab, re),\n",
    "            \"train_set.json\")\n",
    "        \n",
    "        eval_q=[]\n",
    "        eval_a={}\n",
    "        for i in eval_qa:\n",
    "            \n",
    "            eval_q.append(test_qa(\n",
    "                train_qa[i]['qas'][0]['id'],\n",
    "                train_qa[i]['qas'][0]['question'],\n",
    "                train_qa[i]['context']))\n",
    "            eval_a[train_qa[i]['qas'][0]['id']] = train_qa[i]['qas'][0]['answers']\n",
    "            \n",
    "        bset(\n",
    "            eval_q, \n",
    "            \"eval/evl_%s/output_%s/\" % (col_ab, re), \n",
    "            \"test_set.json\")\n",
    "        json.dump(eval_a, open(\"eval/evl_%s/input_%s/eval_set.json\" \n",
    "        % (col_ab, re), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ab =  \"pat\"\n",
    "standard_0 = pd.DataFrame(np.zeros((0,1)), columns = [\"golden\"])\n",
    "prediction_0 = pd.DataFrame(np.zeros((0,3)), columns = [\"prediction\",\"rate\",\"cut\"])\n",
    "for re in range(1,11):\n",
    "    eval_a = json.load(open(\"eval/evl_%s/input_%s/eval_set.json\" % (col_ab, re), \"r\"))\n",
    "    standard = pd.DataFrame(eval_a, index=[\"golden\"]).T\n",
    "    standard_0 = pd.concat((standard_0, standard), 0)\n",
    "    prediction = json.load(open(\"eval/evl_%s/output_%s/predictions_.json\" % (col_ab, re),'r'))\n",
    "    prediction = pd.DataFrame(prediction, index=[\"prediction\", \"rate\"]).T\n",
    "    prediction[\"cut\"] = 1\n",
    "    for idx in prediction.index:\n",
    "        prediction.loc[idx, \"rate\"] = prediction.loc[idx, \"rate\"][0]\n",
    "        prediction.loc[idx, \"cut\"] = 1 - prediction.loc[idx, \"rate\"]\n",
    "        if prediction.loc[idx, \"rate\"] < 0.85:\n",
    "            prediction.loc[idx, \"prediction\"] = \"no\"\n",
    "    prediction_0 = pd.concat((prediction_0, prediction),0)\n",
    "\n",
    "fig_path = (\"eval/evl_%s/output_%s\" % (col_ab, re))\n",
    "eval.evaluate(standard_0, prediction_0, fig_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia = {\"bronchitis\",\"bronchopneumonia\",\"pneumonia\",\"pneumonitis\",\"pneumonic\",\"pleuropneumonia\",\"pleural\"}\n",
    "LungRelated = {\"bronchus\",\"bronchial\",\"tracheobronchial\",\"bronchiolar\",      \"bronchopulmonary\",\n",
    "               \"bronchoalveolar\",\"bronchoscopy\",\n",
    "               \"lung\",\"pulmonary\",\"pneumonic\",\"bronchopulmonary\",\"respiratory\",\"respiration\"}\n",
    "infection = {\"infection\",\"infections\",\"abscess\",\"pathology\",\"etiology\",  \"diseases\",\n",
    "             \"bacteremia\",\"sepsis\",\"septic\",\"pathogenicity\",\"legionellosis\",\"empyema\",\"necrosis\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/data/t070224/Pubmed/Pubmed_Label/3.Orgnize/output/文献合并/human_label_pat.xlsx\")\n",
    "df['golden'] = 'no'\n",
    "df.loc[df[\"是否是致病菌\"]=='yes', \"golden\"] = 'yes'\n",
    "df[\"full\"] = df[\"Full\"].str.lower()\n",
    "df[\"prediction\"] = 'no'\n",
    "for aword in pneumonia:\n",
    "    df.loc[df[\"full\"].str.contains(aword), \"prediction\"] = 'yes'\n",
    "    print(aword, df.loc[df[\"full\"].str.contains(aword), ['golden','prediction', 'Full','原文链接']])\n",
    "for aword in LungRelated:\n",
    "    for bword in infection:\n",
    "        df.loc[(df[\"full\"].str.contains(aword)) & (df[\"full\"].str.contains(bword)) , \"prediction\"] = 'yes'\n",
    "        print(aword, df.loc[df[\"full\"].str.contains(aword), ['golden','prediction', 'Full','原文链接']])\n",
    "fig_path = ''\n",
    "eval.evaluate(df[['golden']], df[['prediction']], fig_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 免疫状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/data/t070224/Pubmed/Pubmed_Label/3.Orgnize/output/文献合并/human_label_pat.xlsx\")\n",
    "df = df.loc[df[\"是否是致病菌\"]=='yes', :]\n",
    "df['golden'] = 'no'\n",
    "df.loc[df[\"免疫状态\"]=='抑制', \"golden\"] = 'yes'\n",
    "df[\"full\"] = df[\"Full\"].str.lower()\n",
    "df[\"prediction\"] = 'no'\n",
    "for aword in [\n",
    "    # \"immunodeficiency\", \n",
    "    \"immunocompromised\", \"immunosuppressive\",\"immunosuppression\", \n",
    "    # \"compromised\", \"suppressed\", \"supperssive\", \"suppression\",\n",
    "    \"hiv\",\"hiv-positive\",\"aids\",\n",
    "    \"transplantation\", \"transplanted\",\n",
    "    \"malignancy\", \"cancer\", \"carcinoma\", \n",
    "    \"leukemia\",\"leukaemia\", \"lymphoma\", \"melanoma\", \"myeloma\",\n",
    "    \"impair\", \"impaired immune\", \"fibrosis\"]:\n",
    "    df.loc[df[\"full\"].str.contains(aword), \"prediction\"] = 'yes'\n",
    "    # print(aword, df.loc[df[\"full\"].str.contains(aword), ['golden','prediction', 'Full','原文链接']])\n",
    "for aword in [\"immunocompetent\"]:\n",
    "    df.loc[df[\"full\"].str.contains(aword), \"prediction\"] = 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果: 0.7985347985347986 0.651685393258427 0.7073170731707317 0.6783625730994152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7985347985347986, 0.651685393258427, 0.7073170731707317, 0.6783625730994152)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.evaluate(df[['golden']], df[['prediction']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/data/t070224/Pubmed/Pubmed_Label/3.Orgnize/output/文献合并/human_label_pat.xlsx\")\n",
    "df = df.loc[df[\"是否是致病菌\"]=='yes', :]\n",
    "df['golden'] = 'no'\n",
    "df.loc[df[\"预后\"]=='死亡', \"golden\"] = 'yes'\n",
    "df[\"full\"] = df[\"Full\"].str.lower()\n",
    "df[\"prediction\"] = 'no'\n",
    "for aword in [\n",
    "    'death', 'dead']:\n",
    "    df.loc[df[\"full\"].str.contains(aword), \"prediction\"] = 'yes'\n",
    "    print(aword, df.loc[df[\"full\"].str.contains(aword), ['golden','prediction', 'Full','原文链接']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果: 0.8992673992673993 0.5161290322580645 0.2857142857142857 0.367816091954023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/t070224/Pubmed/Pubmed_Bert/eval.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  standard.loc[standard[\"golden\"] == \"yes\", \"golden\"] = 1\n",
      "/home/data/t070224/Pubmed/Pubmed_Bert/eval.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  standard.loc[standard[\"golden\"] == \"no\", \"golden\"] = 0\n",
      "/home/data/t070224/Pubmed/Pubmed_Bert/eval.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  standard[\"minus\"] = 1 - standard[\"golden\"]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['rate', 'cut'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/data/t070224/Pubmed/Pubmed_Bert/eval_kw.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbiotrainee.vip/home/data/t070224/Pubmed/Pubmed_Bert/eval_kw.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fig_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbiotrainee.vip/home/data/t070224/Pubmed/Pubmed_Bert/eval_kw.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(df[[\u001b[39m'\u001b[39;49m\u001b[39mgolden\u001b[39;49m\u001b[39m'\u001b[39;49m]], df[[\u001b[39m'\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m'\u001b[39;49m]], fig_path)\n",
      "File \u001b[0;32m~/Pubmed/Pubmed_Bert/eval.py:61\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(standard, prediction, fig_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m standard[\u001b[39m\"\u001b[39m\u001b[39mminus\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m standard[\u001b[39m\"\u001b[39m\u001b[39mgolden\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     59\u001b[0m standard_v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(standard\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m prediction \u001b[39m=\u001b[39m prediction[[\u001b[39m\"\u001b[39;49m\u001b[39mrate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mcut\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[1;32m     62\u001b[0m prediction\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mgolden\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mminus\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     63\u001b[0m prediction_v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(prediction\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['rate', 'cut'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "fig_path = ''\n",
    "eval.evaluate(df[['golden']], df[['prediction']], fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd5a5980a31967086eaababc5338e6a92d5792ba40cc4c910227acd610a4f48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
