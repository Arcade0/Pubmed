{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b8c145-09be-4e25-a8c5-e6b6973c4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import eval\n",
    "from mkdir import mk_dir\n",
    "from bert_format import bset, train_yn, test_yn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9240c522",
   "metadata": {},
   "source": [
    "# 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe00a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"/home/data/t070224/Pubmed/Pubmed_Label/3.Orgnize/output/文献合并\"\n",
    "col_dic = {\"是否是致病菌\":\"pat\",\"免疫状态\":\"immu\",\"预后\":\"oc\"}\n",
    "\n",
    "for col_name, col_ab in col_dic.items():\n",
    "    train_qa = []\n",
    "    # 读取标注信息\n",
    "    df = pd.read_excel(\"%s/human_label_pat.xlsx\" % (label_path), header=0)\n",
    "    \n",
    "    # 设置问题\n",
    "    if col_name == \"是否是致病菌\":\n",
    "        que = []\n",
    "        for idx in df.index:\n",
    "            que.append('Can %s cause pneumonia?' % df.loc[idx, \"物种名称\"])\n",
    "    if col_name == \"免疫状态\":\n",
    "        df = df.loc[df[\"是否是致病菌\"] == \"yes\", :]\n",
    "        df.loc[df[col_name] == \"抑制\", col_name] = \"yes\"\n",
    "        que = 'Is patient immunocompromised?'\n",
    "    if col_name == \"预后\":\n",
    "        df = df.loc[df[\"是否是致病菌\"] == \"yes\", :]\n",
    "        df.loc[df[col_name] == \"死亡\", col_name] = \"yes\"\n",
    "        que = 'Is patient dead?'\n",
    "    \n",
    "    df.loc[df[col_name] != \"yes\", col_name] = \"no\"    \n",
    "    df[\"question\"] = que\n",
    "    \n",
    "    # 创建QA样本  \n",
    "    for idx in df.index:\n",
    "        train_qa.append(train_yn(\n",
    "            '%s:%s' % (df.loc[idx, \"ID\"], df.loc[idx, \"物种名称\"]),\n",
    "            df.loc[idx, \"question\"],\n",
    "            '%s' % df.loc[idx, col_name],\n",
    "            '%s' % df.loc[idx, \"Full\"]))\n",
    "    bset(train_qa, \"input/input_%s/\"%(col_ab), \"train_set.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f9e6c8-cfcf-47df-9ded-e1e40f96d9ca",
   "metadata": {},
   "source": [
    "#  测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8755773-c08b-4bd5-9b60-1ad3f03cf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/data/t070224/Pubmed/Pubmed_Search/search_results/search_results_hanimals.txt\",\"r\") as f:\n",
    "    content = f.read()\n",
    "    spec_papers_dic = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68915130-4d20-436d-8425-07446563e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测样本格式转换\n",
    "papers_l = {}\n",
    "for spec_type in spec_papers_dic:\n",
    "\n",
    "    for spec,spec_papers in spec_papers_dic[spec_type].items():\n",
    "        \n",
    "        for paper_id, paper in spec_papers.items():\n",
    "            \n",
    "            papers_l['%s:%s' % (paper_id, spec)] = paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8ddad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qa = []\n",
    "for paper_id,paper in papers_l.items():     \n",
    "    if len(paper[\"texts\"][\"Ab\"]) > 0:\n",
    "        test_qa.append(\n",
    "            test_yn(\n",
    "                paper_id, \n",
    "                'Can %s cause Pneumonia?' % paper_id.split(\":\")[-1],\n",
    "                paper[\"texts\"][\"Ab\"]+\" \"+\" \".join(sum(paper[\"Meshhead\"],[]))))\n",
    "bset(test_qa,\"input/input_pat/\",\"test_qa.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d58a6",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"output/eval_prediction.csv\", index_col=0)\n",
    "train_data = train_data[~train_data.index.duplicated(keep='first')]\n",
    "standard_0 = pd.read_csv(\"output/eval_standards.csv\", index_col=0)\n",
    "standard_0 = standard_0[~standard_0.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edae6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia = {\"bronchitis\",\"bronchopneumonia\",\"pneumonia\",\"pneumonitis\",\"pneumonic\",\"pleuropneumonia\",\"pleural\"}\n",
    "LungRelated = {\"bronchus\",\"bronchial\",\"tracheobronchial\",\"bronchiolar\",\"bronchopulmonary\",\n",
    "               \"bronchoalveolar\",\"bronchoscopy\",\n",
    "               \"lung\",\"pulmonary\",\"pneumonic\",\"bronchopulmonary\",\"respiratory\",\"respiration\"}\n",
    "infection = {\"infection\",\"infections\",\"abscess\",\"pathology\",\"etiology\",\"diseases\",\n",
    "             \"bacteremia\",\"sepsis\",\"septic\",\"pathogenicity\",\"legionellosis\",\"empyema\",\"necrosis\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extend = {}\n",
    "for i in train_data.index:\n",
    "    if i.lower() in papers_l:\n",
    "        train_extend[i] = papers_l[i.lower()]\n",
    "    else:\n",
    "        print(train_data.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a42bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = {}\n",
    "for paper_id, paper in train_extend.items():\n",
    "    spec = paper_id.split(\":\")[1].lower()\n",
    "    text = paper[\"texts\"][\"Ab\"] +\" \"+\" \".join(sum(paper[\"Meshhead\"],[])) # 添加mesh词汇\n",
    "    text = text.translate(str.maketrans(string.punctuation, \" \"*32,)).replace(\"  \", \" \")\n",
    "    text = text.lower()\n",
    "    words = set(text.split(\" \"))\n",
    "    if len(words & pneumonia) > 0:\n",
    "        if \"colonization\" not in words:\n",
    "            if \"%s / isolation & purification\" % spec not in \" / \".join(sum(paper[\"Meshhead\"],[])).lower():\n",
    "                pats[paper_id] = paper\n",
    "    else:\n",
    "        if len(words & LungRelated) > 0:\n",
    "            if len(words & infection) > 0:\n",
    "                if \"colonization\" not in words:\n",
    "                    if \"%s / isolation & purification\" % spec not in \" / \".join(sum(paper[\"Meshhead\"],[])).lower():\n",
    "                        pats[paper_id] = paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572334b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 0.5\n",
    "train_data.loc[train_data[\"rate\"]>=cut, \"prediction\"] = \"yes\"\n",
    "train_data.loc[train_data[\"rate\"]<cut, \"prediction\"] = \"no\"\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    if train_data.index[i] not in pats:\n",
    "        if train_data[\"prediction\"][i] == 'yes':\n",
    "            train_data[\"prediction\"][i] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573c401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction_0 = train_data\n",
    "prediction_0.loc[prediction_0[\"prediction\"]==\"yes\", \"prediction\"] = 1\n",
    "prediction_0.loc[prediction_0[\"prediction\"]==\"no\", \"prediction\"] = 0\n",
    "prediction_0 = prediction_0.astype(np.int64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd5a5980a31967086eaababc5338e6a92d5792ba40cc4c910227acd610a4f48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
